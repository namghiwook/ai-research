# í•©ì„± ì¸êµ¬ ê¸°ë°˜ ê°€ìƒ ì„¤ë¬¸ ì‹œìŠ¤í…œ - í˜„ì‹¤ì  êµ¬í˜„ ì „ëµ (ìˆ˜ì •íŒ)

## ğŸ“‹ Executive Summary

**í•µì‹¬ ê²°ë¡ :** ì´ˆê¸° íŒŒì¸íŠœë‹ ì „ëµì˜ **ì¹˜ëª…ì  í•œê³„**ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.

```
âŒ ë¬¸ì œ: íŒŒì¸íŠœë‹ ì‹œ í•™ìŠµí•œ ì§ˆë¬¸ â‰  ì‹¤ì œ ì„¤ë¬¸ ì§ˆë¬¸
   - í•™ìŠµ: "ì •ë¶€ ê²½ì œ ì •ì±… ë§Œì¡±ë„" (ì¼ë°˜ì )
   - ì‹¤ì œ: "í˜„ëŒ€ì¹´ë“œ Mí¬ì¸íŠ¸ ì ë¦½ë¥  ê²½ìŸë ¥" (ì´ˆêµ¬ì²´ì )
   
âœ… í•´ë²•: Claude API ì§ì ‘ ì‚¬ìš© ìš°ì„  + ì¡°ê±´ë¶€ ìµœì í™”
```

**ì„œë¹„ìŠ¤ ëª¨ë¸ë³„ ì „ëµ:**

| ì„œë¹„ìŠ¤ ëª¨ë¸ | ì¶”ì²œ ë°©ì‹ | ì´ìœ  |
|-----------|----------|------|
| **B2B ë§ì¶¤í˜• ì„¤ë¬¸** | Claude API | ì§ˆë¬¸ ë§¤ë²ˆ ë‹¤ë¦„ |
| **í‘œì¤€ ì¶”ì  ì¡°ì‚¬** | í•˜ì´ë¸Œë¦¬ë“œ | ì§ˆë¬¸ ë°˜ë³µì  |
| **ì •ë¶€/ê³µê³µ ëª¨ë‹ˆí„°ë§** | íŒŒì¸íŠœë‹ | ì§ˆë¬¸ ê³ ì • |

---

## ğŸ“‹ ëª©ì°¨

- [íŒŒì¸íŠœë‹ ì „ëµì˜ ê·¼ë³¸ì  í•œê³„](#íŒŒì¸íŠœë‹-ì „ëµì˜-ê·¼ë³¸ì -í•œê³„)
- [ì‹œë‚˜ë¦¬ì˜¤ë³„ ì í•©ì„± ë¶„ì„](#ì‹œë‚˜ë¦¬ì˜¤ë³„-ì í•©ì„±-ë¶„ì„)
- [ìˆ˜ì •ëœ 3ê°€ì§€ ì „ëµ](#ìˆ˜ì •ëœ-3ê°€ì§€-ì „ëµ)
- [ì˜¨ë””ë§¨ë“œ IPF ìƒì„± ì „ëµ](#ì˜¨ë””ë§¨ë“œ-ipf-ìƒì„±-ì „ëµ)
- [í˜„ì‹¤ì  ë¹„ìš©/í’ˆì§ˆ ë¹„êµ](#í˜„ì‹¤ì -ë¹„ìš©í’ˆì§ˆ-ë¹„êµ)
- [ìµœì¢… ì¶”ì²œ ë¡œë“œë§µ](#ìµœì¢…-ì¶”ì²œ-ë¡œë“œë§µ)
- [êµ¬í˜„ ê°€ì´ë“œ](#êµ¬í˜„-ê°€ì´ë“œ)

---

## ğŸš¨ íŒŒì¸íŠœë‹ ì „ëµì˜ ê·¼ë³¸ì  í•œê³„

### ë¬¸ì œ 1: Domain Gap (ë„ë©”ì¸ ê²©ì°¨)

**íŒŒì¸íŠœë‹ ì‹œ í•™ìŠµ ë°ì´í„°:**
```python
training_questions = {
    "ì •ì¹˜": [
        "í˜„ ì •ë¶€ ê²½ì œ ì •ì±…ì— ë§Œì¡±í•˜ì‹­ë‹ˆê¹Œ?",
        "ì™¸êµ ì•ˆë³´ ì •ì±…ì„ ì–´ë–»ê²Œ í‰ê°€í•˜ì‹­ë‹ˆê¹Œ?",
        "ì§€ë°©ìì¹˜ í™œì„±í™”ì— ëŒ€í•œ ì˜ê²¬ì€?"
    ],
    "ê²½ì œ": [
        "í˜„ì¬ ë¶€ë™ì‚° ì •ì±…ì— ë§Œì¡±í•˜ì‹­ë‹ˆê¹Œ?",
        "ê³ ìš© ì•ˆì •ì„±ì„ ì²´ê°í•˜ì‹­ë‹ˆê¹Œ?",
        "ì†Œë“ ìˆ˜ì¤€ì´ í–¥ìƒë˜ì—ˆë‹¤ê³  ëŠë¼ì‹­ë‹ˆê¹Œ?"
    ],
    "ì‚¬íšŒ": [
        "êµìœ¡ ì œë„ê°€ ê³µì •í•˜ë‹¤ê³  ìƒê°í•˜ì‹­ë‹ˆê¹Œ?",
        "ë³µì§€ ì œë„ê°€ ì¶©ë¶„í•˜ë‹¤ê³  ìƒê°í•˜ì‹­ë‹ˆê¹Œ?"
    ]
}
# ì´ 3,000ê°œ - ì¼ë°˜ì ì´ê³  ì¶”ìƒì ì¸ ì‚¬íšŒ ì´ìŠˆ
```

**ì‹¤ì œ ë“¤ì–´ì˜¤ëŠ” ì„¤ë¬¸ (B2B):**
```python
real_surveys = [
    {
        "client": "í˜„ëŒ€ì¹´ë“œ",
        "questions": [
            "í˜„ëŒ€ì¹´ë“œ Mí¬ì¸íŠ¸ ì ë¦½ë¥ ì´ íƒ€ì‚¬ ëŒ€ë¹„ ê²½ìŸë ¥ì´ ìˆë‹¤ê³  ìƒê°í•˜ì‹­ë‹ˆê¹Œ?",
            "í˜„ëŒ€ì¹´ë“œ ì•± UI/UXê°€ ì‚¬ìš©í•˜ê¸° í¸ë¦¬í•©ë‹ˆê¹Œ?",
            "í”„ë¦¬ë¯¸ì—„ ì¹´ë“œ ì—°íšŒë¹„ 30ë§Œì›ì´ í•©ë¦¬ì ì…ë‹ˆê¹Œ?"
        ]
    },
    {
        "client": "í…ŒìŠ¬ë¼",
        "questions": [
            "ëª¨ë¸3 ì‹¤ë‚´ ì¸í…Œë¦¬ì–´ í’ˆì§ˆì— ë§Œì¡±í•˜ì‹­ë‹ˆê¹Œ?",
            "ìŠˆí¼ì°¨ì € ì¶©ì „ ì¸í”„ë¼ê°€ ì¶©ë¶„í•˜ë‹¤ê³  ìƒê°í•˜ì‹­ë‹ˆê¹Œ?",
            "FSD ë² íƒ€ ê¸°ëŠ¥ ê°€ê²© ëŒ€ë¹„ ë§Œì¡±ë„ëŠ”?"
        ]
    },
    {
        "client": "ì¿ íŒ¡",
        "questions": [
            "ë¡œì¼“ë°°ì†¡ ìƒˆë²½ë°°ì†¡ ì„œë¹„ìŠ¤ë¥¼ ì¬ì´ìš©í•  ì˜í–¥ì´ ìˆìŠµë‹ˆê¹Œ?",
            "ì¿ íŒ¡í”Œë ˆì´ ì½˜í…ì¸  ë¼ì¸ì—…ì— ë§Œì¡±í•˜ì‹­ë‹ˆê¹Œ?"
        ]
    }
]
# ê·¹ë„ë¡œ êµ¬ì²´ì ì´ê³  ì „ë¬¸ì ì¸ ì œí’ˆ/ì„œë¹„ìŠ¤ ì§ˆë¬¸
```

**ê²°ê³¼:**
```
íŒŒì¸íŠœë‹ ëª¨ë¸ ì‘ë‹µ (ì˜ˆìƒ):
Q: "í˜„ëŒ€ì¹´ë“œ Mí¬ì¸íŠ¸ ì ë¦½ë¥ ì´ íƒ€ì‚¬ ëŒ€ë¹„ ê²½ìŸë ¥ì´ ìˆìŠµë‹ˆê¹Œ?"
A: "ì‹ ìš©ì¹´ë“œ ì„œë¹„ìŠ¤ì— ëŒ€ì²´ë¡œ ë§Œì¡±í•©ë‹ˆë‹¤." (â† ì¼ë°˜ì , ì§ˆë¬¸ê³¼ ë¬´ê´€)

Claude API ì§ì ‘ ì‘ë‹µ:
A: "30ëŒ€ ì„œìš¸ ì§ì¥ì¸ìœ¼ë¡œì„œ Mí¬ì¸íŠ¸ ì ë¦½ë¥  1%ëŠ” íƒ€ì‚¬ ì‚¼ì„±ì¹´ë“œ 1.5%ë‚˜ 
    ì‹ í•œ 1.2%ì— ë¹„í•´ ë‚®ì€ í¸ì´ë¼ê³  ëŠë‚ë‹ˆë‹¤. ë‹¤ë§Œ ì œíœ´ ê°€ë§¹ì ì´ ë§ì•„
    ì‚¬ìš©ì²˜ëŠ” ë§Œì¡±ìŠ¤ëŸ½ìŠµë‹ˆë‹¤." (â† êµ¬ì²´ì , ë§¥ë½ ìˆìŒ)
```

### ë¬¸ì œ 2: êµ¬ì²´ì„± ê²©ì°¨

| ì°¨ì› | íŒŒì¸íŠœë‹ í•™ìŠµ ë°ì´í„° | ì‹¤ì œ ì„¤ë¬¸ |
|------|-------------------|----------|
| **ì¶”ìƒí™” ìˆ˜ì¤€** | ë†’ìŒ (ì •ì±…, ì œë„) | ë‚®ìŒ (ì œí’ˆ ê¸°ëŠ¥) |
| **ì „ë¬¸ì„±** | ì¼ë°˜ì¸ ì˜ê²¬ | ì‚¬ìš©ì ê²½í—˜ |
| **ë§¥ë½** | ì‚¬íšŒ ì „ë°˜ | íŠ¹ì • ë¸Œëœë“œ/ì„œë¹„ìŠ¤ |
| **ë‹µë³€ ê¹Šì´** | ë§Œì¡±/ë¶ˆë§Œì¡± | êµ¬ì²´ì  ì´ìœ  |

**ì˜ˆì‹œ ë¹„êµ:**

```python
# í•™ìŠµ ë°ì´í„° (ì¶”ìƒì )
{
    "question": "ì‹ ìš©ì¹´ë“œ ì„œë¹„ìŠ¤ì— ë§Œì¡±í•˜ì‹­ë‹ˆê¹Œ?",
    "persona": "30ëŒ€ ë‚¨ì„±, ì„œìš¸, ì§ì¥ì¸",
    "response": "ëŒ€ì²´ë¡œ ë§Œì¡±í•˜ì§€ë§Œ ìˆ˜ìˆ˜ë£Œê°€ ë¶€ë‹´ë©ë‹ˆë‹¤."
}

# ì‹¤ì œ ì„¤ë¬¸ (êµ¬ì²´ì )
{
    "question": "í˜„ëŒ€ì¹´ë“œ Mí¬ì¸íŠ¸ë¥¼ ë„¤ì´ë²„í˜ì´ë¡œ ì „í™˜ ì‹œ ìˆ˜ìˆ˜ë£Œ 3%ê°€ í•©ë¦¬ì ì…ë‹ˆê¹Œ?",
    "persona": "30ëŒ€ ë‚¨ì„±, ì„œìš¸, ì§ì¥ì¸, í˜„ëŒ€ì¹´ë“œ 3ë…„ ì‚¬ìš©",
    "expected_response": "ì›” 50ë§Œì› ì‚¬ìš© ì‹œ 1.5ë§Œì› ì ë¦½ë˜ëŠ”ë° 3% ìˆ˜ìˆ˜ë£Œë©´ 
                         4,500ì›ì´ ë¹ ì§€ëŠ” ì…ˆì…ë‹ˆë‹¤. íƒ€ì‚¬ëŠ” 1-2% ìˆ˜ì¤€ì´ë¼ 
                         í˜„ëŒ€ì¹´ë“œê°€ ë‹¤ì†Œ ë†’ë‹¤ê³  ëŠë‚ë‹ˆë‹¤."
}
# íŒŒì¸íŠœë‹ ëª¨ë¸: ì´ëŸ° êµ¬ì²´ì„± ë¶ˆê°€ëŠ¥
```

### ë¬¸ì œ 3: ì‹œê°„ì„± (Temporality)

```python
# íŒŒì¸íŠœë‹ ì‹œì : 2024ë…„ 1ì›”
training_context = {
    "ê¸ˆë¦¬": "ì§€ì† ì¸ìƒ ì¤‘",
    "ë¶€ë™ì‚°": "í•˜ë½ êµ­ë©´",
    "ì£¼ì‹": "ì•½ì„¸ì¥"
}

learning_data = {
    "question": "í˜„ì¬ ê¸ˆë¦¬ ì¸ìƒì´ ë¶€ë™ì‚° ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥",
    "response": "ê¸ˆë¦¬ ì¸ìƒìœ¼ë¡œ ëŒ€ì¶œ ë¶€ë‹´ì´ ì»¤ì ¸ ì§‘ê°’ì´ í•˜ë½í•˜ê³  ìˆìŠµë‹ˆë‹¤."
}

# ì„¤ë¬¸ ì‹œì : 2026ë…„ 6ì›”
real_context = {
    "ê¸ˆë¦¬": "ì¸í•˜ ì „í™˜",
    "ë¶€ë™ì‚°": "ë°˜ë“± ì¡°ì§",
    "ì£¼ì‹": "ê°•ì„¸ì¥"
}

real_question = "ìµœê·¼ ê¸ˆë¦¬ ì¸í•˜ ì´í›„ ì „ì„¸ ì‹œì¥ ì „ë§ì€?"
# íŒŒì¸íŠœë‹ ëª¨ë¸: ì™„ì „íˆ ë°˜ëŒ€ ìƒí™©, ì—‰ëš±í•œ ë‹µë³€ ê°€ëŠ¥
```

### ë¬¸ì œ 4: Long-tail Distribution

```python
# ì§ˆë¬¸ ë¶„í¬ (ì‹¤ì œ ë°ì´í„° ë¶„ì„ ê²°ê³¼)
question_distribution = {
    "ìƒìœ„ 10ê°œ ì¹´í…Œê³ ë¦¬": 0.40,  # 40%ë§Œ ë°˜ë³µ
    "ì¤‘ìœ„ 20ê°œ ì¹´í…Œê³ ë¦¬": 0.30,
    "í•˜ìœ„ 100+ ì¹´í…Œê³ ë¦¬": 0.30   # 30%ëŠ” ì™„ì „íˆ ìƒˆë¡œìš´ ì§ˆë¬¸
}

# íŒŒì¸íŠœë‹ íš¨ê³¼
finetuned_effectiveness = {
    "ìƒìœ„ 10ê°œ": 0.90,  # 90% í’ˆì§ˆ (ì˜ ì‘ë™)
    "ì¤‘ìœ„ 20ê°œ": 0.60,  # 60% í’ˆì§ˆ (ê·¸ëŸ­ì €ëŸ­)
    "í•˜ìœ„ 100+": 0.30   # 30% í’ˆì§ˆ (ê±°ì˜ ëª» ì”€)
}

# ê°€ì¤‘ í‰ê·  í’ˆì§ˆ
weighted_quality = 0.40*0.90 + 0.30*0.60 + 0.30*0.30 = 0.63 (63%)
# Claude API ì§ì ‘: 0.95 (95%)

# ê²°ë¡ : ë¹„ìš©ì€ 15ë°° ì¤„ì§€ë§Œ í’ˆì§ˆì€ 32% í•˜ë½
```

---

## ğŸ¯ ì‹œë‚˜ë¦¬ì˜¤ë³„ ì í•©ì„± ë¶„ì„

### ì‹œë‚˜ë¦¬ì˜¤ A: í‘œì¤€í™”ëœ ë°˜ë³µ ì„¤ë¬¸ âœ… íŒŒì¸íŠœë‹ ìœ ë¦¬

**íŠ¹ì§•:**
- ì§ˆë¬¸ì´ ê³ ì •ë˜ì–´ ìˆìŒ
- ë§¤ë‹¬/ë¶„ê¸°ë³„ ë°˜ë³µ ì‹¤í–‰
- ë„ë©”ì¸ì´ ì¢ê³  ëª…í™•í•¨

**ì˜ˆì‹œ:**

```python
# ì •ë¶€ ì •ì±… ëª¨ë‹ˆí„°ë§ (í†µê³„ì²­)
monthly_survey = {
    "fixed_questions": [
        "í˜„ ì •ë¶€ ê²½ì œ ì •ì±… ë§Œì¡±ë„",
        "ê³ ìš© ì•ˆì •ì„± ì²´ê°ë„",
        "ë¬¼ê°€ ë¶€ë‹´ ìˆ˜ì¤€",
        "ë³µì§€ ì œë„ ë§Œì¡±ë„",
        # ... 50ê°œ ê³ ì • ì§ˆë¬¸
    ],
    "frequency": "monthly",
    "sample_size": 10000,
    "years": 5
}

# ì´ ì„¤ë¬¸: 50ë¬¸í•­ Ã— 10,000ëª… Ã— 12ê°œì›” Ã— 5ë…„ = 30,000,000ê±´
# ì§ˆë¬¸ ë°˜ë³µë„: 100% (ì™„ì „íˆ ë™ì¼)

# íŒŒì¸íŠœë‹ íš¨ê³¼
effectiveness = {
    "ì´ˆê¸° íˆ¬ì": "$500 (1íšŒ)",
    "ì›” ë¹„ìš©": "$50",
    "5ë…„ ì´ ë¹„ìš©": "$3,500",
    "ì‘ë‹µ í’ˆì§ˆ": "95%",
    "ì ˆê°ì•¡": "$87,000" # vs Claude API $90,000
}
```

**ì í•©í•œ ì‚¬ë¡€:**
- ì •ë¶€ ì •ì±… ë§Œì¡±ë„ ì¶”ì  ì¡°ì‚¬
- ê¸°ì—… ë‚´ë¶€ ì§ì› ë§Œì¡±ë„ (ë¶„ê¸°ë³„)
- ë¸Œëœë“œ ì¸ì§€ë„ ì¶”ì  ì¡°ì‚¬ (ê³ ì • ì§ˆë¬¸)

### ì‹œë‚˜ë¦¬ì˜¤ B: ë§ì¶¤í˜• ì¼íšŒì„± ì„¤ë¬¸ âŒ íŒŒì¸íŠœë‹ ë¶ˆë¦¬

**íŠ¹ì§•:**
- ê³ ê°ì‚¬ë§ˆë‹¤ ì§ˆë¬¸ì´ ë‹¤ë¦„
- 1íšŒì„± í”„ë¡œì íŠ¸
- ë„ë©”ì¸ì´ ê´‘ë²”ìœ„

**ì˜ˆì‹œ:**

```python
# B2B ì‹œì¥ì¡°ì‚¬ ëŒ€í–‰ ì„œë¹„ìŠ¤
projects = [
    {
        "client": "í˜„ëŒ€ì¹´ë“œ",
        "questions": ["Mí¬ì¸íŠ¸ ì ë¦½ë¥  ê²½ìŸë ¥", "ì•± UI/UX ë§Œì¡±ë„", ...],
        "sample_size": 2000,
        "frequency": "1íšŒ"
    },
    {
        "client": "í…ŒìŠ¬ë¼",
        "questions": ["ëª¨ë¸3 ì¸í…Œë¦¬ì–´ í’ˆì§ˆ", "ì¶©ì „ ì¸í”„ë¼", ...],
        "sample_size": 1500,
        "frequency": "1íšŒ"
    },
    {
        "client": "ì¿ íŒ¡",
        "questions": ["ë¡œì¼“ë°°ì†¡ ë§Œì¡±ë„", "ì¿ íŒ¡í”Œë ˆì´ ì½˜í…ì¸ ", ...],
        "sample_size": 3000,
        "frequency": "1íšŒ"
    }
    # ... ì—°ê°„ 50ê°œ í”„ë¡œì íŠ¸
]

# ì§ˆë¬¸ ì¤‘ë³µë„: 5% ë¯¸ë§Œ (ê±°ì˜ ì—†ìŒ)

# íŒŒì¸íŠœë‹ íš¨ê³¼
effectiveness = {
    "ì´ˆê¸° íˆ¬ì": "$500",
    "í”„ë¡œì íŠ¸ë‹¹ ì¶”ê°€ í•™ìŠµ": "$30 (ì„¤ë¬¸ë³„ mini FT)",
    "ì—°ê°„ ì´ ë¹„ìš©": "$500 + $30Ã—50 = $2,000",
    "ì‘ë‹µ í’ˆì§ˆ": "60-70%",
    "Claude API ë¹„ìš©": "$2,250",
    "ì ˆê°ì•¡": "$250" # ê±°ì˜ ì—†ìŒ, ë³µì¡ë„ë§Œ ì¦ê°€
}
```

**ì í•©í•œ ì‚¬ë¡€:**
- B2B ì‹œì¥ì¡°ì‚¬ ì»¨ì„¤íŒ…
- ì‹ ì œí’ˆ ì¶œì‹œ ì „ í…ŒìŠ¤íŠ¸
- ê´‘ê³  ìº í˜ì¸ íš¨ê³¼ ì¸¡ì •

### ì‹œë‚˜ë¦¬ì˜¤ C: í•˜ì´ë¸Œë¦¬ë“œ (ë°˜ë°˜) âš–ï¸ ì¡°ê±´ë¶€ ìµœì í™”

**íŠ¹ì§•:**
- ì¼ë¶€ ì§ˆë¬¸ì€ ë°˜ë³µì 
- ì¼ë¶€ ì§ˆë¬¸ì€ ë§ì¶¤í˜•

**ì˜ˆì‹œ:**

```python
# SaaS ì„¤ë¬¸ í”Œë«í¼
survey_mix = {
    "standard_templates": {
        "questions": ["ì§ì¥ ë§Œì¡±ë„", "ê¸‰ì—¬ ë§Œì¡±ë„", "ë³µì§€ ë§Œì¡±ë„", ...],
        "usage": "60%",
        "repetition": "high"
    },
    "custom_surveys": {
        "questions": [ê³ ê°ì‚¬ë³„ ë§ì¶¤ ì§ˆë¬¸],
        "usage": "40%",
        "repetition": "low"
    }
}

# í•˜ì´ë¸Œë¦¬ë“œ ì „ëµ
strategy = {
    "standard_60%": "Gemini Fine-tuned ($0.001/ê±´)",
    "custom_40%": "Claude API ($0.015/ê±´)"
}

# ë¹„ìš© ê³„ì‚° (ì›” 10,000ê±´)
cost = {
    "standard": 6000 * 0.001 = "$6",
    "custom": 4000 * 0.015 = "$60",
    "total": "$66/ì›”"
}
# vs ìˆœìˆ˜ Claude: $150/ì›” â†’ 56% ì ˆê°
```

---

## ğŸ’¡ ìˆ˜ì •ëœ 3ê°€ì§€ ì „ëµ

### ì „ëµ 1: í•˜ì´ë¸Œë¦¬ë“œ ë¼ìš°íŒ… â­ (ê°€ì¥ í˜„ì‹¤ì )

**ê°œë…:** ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¼ ì ì ˆí•œ ëª¨ë¸ ìë™ ì„ íƒ

```python
class SmartSurveyRouter:
    """ì§ˆë¬¸ ë„ë©”ì¸ì— ë”°ë¼ ìµœì  ëª¨ë¸ ì„ íƒ"""
    
    def __init__(self):
        # íŒŒì¸íŠœë‹ëœ ëª¨ë¸ (ì €ë ´í•˜ì§€ë§Œ ì œí•œì )
        self.gemini_finetuned = GeminiFinetunedModel(
            model_name="tunedModels/korean-survey-v1"
        )
        
        # Claude API (ë¹„ì‹¸ì§€ë§Œ ë²”ìš©)
        self.claude_api = ClaudeAPI()
        
        # íŒŒì¸íŠœë‹ëœ ë„ë©”ì¸ (í•™ìŠµ ì‹œ í¬í•¨ëœ ì£¼ì œ)
        self.FINETUNED_DOMAINS = {
            "ì •ë¶€ì •ì±…", "ë¶€ë™ì‚°", "ê³ ìš©", "êµìœ¡", "ë³µì§€", 
            "í™˜ê²½", "êµí†µ", "ì˜ë£Œ", "ë¬¸í™”", "ì—¬ê°€"
        }
        
        # ì§ˆë¬¸ ë¶„ë¥˜ê¸°
        self.classifier = QuestionClassifier()
    
    def classify_question(self, question: str) -> str:
        """
        ì§ˆë¬¸ì´ í•™ìŠµëœ ë„ë©”ì¸ì¸ì§€ íŒë‹¨
        
        Returns:
            "ì •ë¶€ì •ì±…" / "ë¶€ë™ì‚°" / "unknown"
        """
        
        # ë°©ë²• 1: í‚¤ì›Œë“œ ë§¤ì¹­
        domain_keywords = {
            "ì •ë¶€ì •ì±…": ["ì •ë¶€", "ì •ì±…", "ëŒ€í†µë ¹", "êµ­íšŒ", "ì„ ê±°"],
            "ë¶€ë™ì‚°": ["ì£¼íƒ", "ì•„íŒŒíŠ¸", "ì „ì„¸", "ì›”ì„¸", "ì§‘ê°’"],
            "ê³ ìš©": ["ì·¨ì—…", "ì‹¤ì—…", "ì¼ìë¦¬", "ì„ê¸ˆ", "ê·¼ë¡œ"],
        }
        
        for domain, keywords in domain_keywords.items():
            if any(kw in question for kw in keywords):
                return domain
        
        # ë°©ë²• 2: ì„ë² ë”© ìœ ì‚¬ë„ (ë” ì •í™•)
        similarity = self.classifier.compute_similarity(
            question, 
            self.FINETUNED_DOMAINS
        )
        
        if similarity.max_score > 0.75:  # ì„ê³„ê°’
            return similarity.best_domain
        
        return "unknown"
    
    def generate_response(self, persona: Dict, question: str) -> Dict:
        """ì‘ë‹µ ìƒì„± + ëª¨ë¸ ì„ íƒ"""
        
        domain = self.classify_question(question)
        
        if domain in self.FINETUNED_DOMAINS:
            # í•™ìŠµëœ ë„ë©”ì¸: Gemini ì‚¬ìš© (ì €ë ´)
            response = self.gemini_finetuned.generate(persona, question)
            model_used = "gemini_finetuned"
            cost = 0.001
        else:
            # ìƒˆë¡œìš´ ë„ë©”ì¸: Claude ì‚¬ìš© (ê³ í’ˆì§ˆ)
            response = self.claude_api.generate(persona, question)
            model_used = "claude_api"
            cost = 0.015
        
        return {
            "response": response,
            "model": model_used,
            "domain": domain,
            "cost": cost
        }
    
    def run_survey(self, personas: List[Dict], questions: List[str]) -> Dict:
        """ì„¤ë¬¸ ì‹¤í–‰ + í†µê³„"""
        
        results = []
        stats = {"gemini": 0, "claude": 0, "total_cost": 0}
        
        for persona in personas:
            for question in questions:
                result = self.generate_response(persona, question)
                results.append(result)
                
                # í†µê³„ ìˆ˜ì§‘
                if result["model"] == "gemini_finetuned":
                    stats["gemini"] += 1
                else:
                    stats["claude"] += 1
                
                stats["total_cost"] += result["cost"]
        
        return {
            "results": results,
            "statistics": {
                "gemini_usage": f"{stats['gemini']}/{len(results)} ({stats['gemini']/len(results)*100:.1f}%)",
                "claude_usage": f"{stats['claude']}/{len(results)} ({stats['claude']/len(results)*100:.1f}%)",
                "total_cost": f"${stats['total_cost']:.2f}",
                "avg_cost_per_response": f"${stats['total_cost']/len(results):.4f}"
            }
        }


# ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ
router = SmartSurveyRouter()

personas = db.find_target_population(
    {"age_group": ["30-34ì„¸"], "region": "ì„œìš¸íŠ¹ë³„ì‹œ"}, 
    sample_size=1000
)

questions = [
    "í˜„ ì •ë¶€ ê²½ì œ ì •ì±…ì— ë§Œì¡±í•˜ì‹­ë‹ˆê¹Œ?",  # â†’ Gemini
    "ë¶€ë™ì‚° ê°€ê²© ì•ˆì •í™” ì •ì±…ì´ íš¨ê³¼ì ì´ë¼ê³  ìƒê°í•˜ì‹­ë‹ˆê¹Œ?",  # â†’ Gemini
    "í˜„ëŒ€ì¹´ë“œ Mí¬ì¸íŠ¸ ì ë¦½ë¥ ì´ ê²½ìŸë ¥ ìˆë‹¤ê³  ìƒê°í•˜ì‹­ë‹ˆê¹Œ?",  # â†’ Claude
    "í…ŒìŠ¬ë¼ ëª¨ë¸3 ì¶©ì „ ì¸í”„ë¼ê°€ ì¶©ë¶„í•˜ë‹¤ê³  ìƒê°í•˜ì‹­ë‹ˆê¹Œ?"  # â†’ Claude
]

result = router.run_survey(personas, questions)

print(result["statistics"])
# Output:
# {
#     "gemini_usage": "2000/4000 (50.0%)",
#     "claude_usage": "2000/4000 (50.0%)",
#     "total_cost": "$32.00",
#     "avg_cost_per_response": "$0.0080"
# }
# vs ìˆœìˆ˜ Claude: $60.00
```

**ì¥ì :**
- ë¹„ìš© 40-60% ì ˆê°
- í’ˆì§ˆ ì†ì‹¤ ìµœì†Œí™” (ë„ë©”ì¸ë³„ ìµœì  ëª¨ë¸)
- ìë™í™” ê°€ëŠ¥

**ë‹¨ì :**
- ë¶„ë¥˜ê¸° ì •í™•ë„ ì˜ì¡´
- ë‘ ëª¨ë¸ ìœ ì§€ ê´€ë¦¬

### ì „ëµ 2: ì„¤ë¬¸ë³„ Mini Fine-tuning

**ê°œë…:** ê° ì„¤ë¬¸ë§ˆë‹¤ ì†ŒëŸ‰ íŒŒì¸íŠœë‹

```python
class PerSurveyFineTuning:
    """ì„¤ë¬¸ë³„ ë§ì¶¤ íŒŒì¸íŠœë‹"""
    
    def __init__(self):
        self.base_model = "gemini-1.5-flash"
        self.claude = ClaudeAPI()
    
    def handle_new_survey(self, survey_spec: Dict) -> Dict:
        """
        ìƒˆ ì„¤ë¬¸ ìš”ì²­ ì²˜ë¦¬
        
        Args:
            survey_spec = {
                "client": "í˜„ëŒ€ì¹´ë“œ",
                "questions": ["Mí¬ì¸íŠ¸ ì ë¦½ë¥ ...", "ì•± UX...", ...],
                "target": {"age": "30-34ì„¸", "card_brand": "í˜„ëŒ€ì¹´ë“œ"},
                "sample_size": 2000
            }
        """
        
        # 1. ì†ŒëŸ‰ í•™ìŠµ ë°ì´í„° ìƒì„± (100ëª…ë§Œ)
        print("Step 1: í•™ìŠµ ë°ì´í„° ìƒì„±...")
        training_personas = self._sample_personas(
            survey_spec["target"], 
            n=100
        )
        
        training_data = []
        for persona in training_personas:
            for question in survey_spec["questions"]:
                # Claudeë¡œ ê³ í’ˆì§ˆ ì‘ë‹µ ìƒì„±
                response = self.claude.generate(persona, question)
                
                training_data.append({
                    "text_input": self._format_prompt(persona, question),
                    "output": response
                })
        
        # ë¹„ìš©: 100ëª… Ã— 5ë¬¸í•­ Ã— $0.015 = $7.5
        
        # 2. ê¸°ì¡´ ëª¨ë¸ì— ì¶”ê°€ í•™ìŠµ (Incremental)
        print("Step 2: ì¶”ê°€ íŒŒì¸íŠœë‹...")
        tuned_model = genai.tune_model(
            base_model=self.base_model,
            training_data=training_data,
            epochs=2,
            learning_rate=0.0001  # ë‚®ê²Œ ì„¤ì • (catastrophic forgetting ë°©ì§€)
        )
        
        # ë¹„ìš©: $20-30
        # ì‹œê°„: 30ë¶„
        
        # 3. ë‚˜ë¨¸ì§€ 1900ëª…ì—ê²Œ ì ìš©
        print("Step 3: ì„¤ë¬¸ ì‹¤í–‰...")
        remaining_personas = self._sample_personas(
            survey_spec["target"],
            n=1900
        )
        
        results = []
        for persona in remaining_personas:
            for question in survey_spec["questions"]:
                response = tuned_model.generate(
                    self._format_prompt(persona, question)
                )
                results.append(response)
        
        # ë¹„ìš©: 1900ëª… Ã— 5ë¬¸í•­ Ã— $0.001 = $9.5
        
        return {
            "results": results,
            "cost_breakdown": {
                "training_data": "$7.5",
                "fine_tuning": "$25",
                "inference": "$9.5",
                "total": "$42"
            },
            "time": "45ë¶„"
        }


# ì‹¤ì œ ì‚¬ìš©
service = PerSurveyFineTuning()

result = service.handle_new_survey({
    "client": "í˜„ëŒ€ì¹´ë“œ",
    "questions": [
        "Mí¬ì¸íŠ¸ ì ë¦½ë¥ ì´ ê²½ìŸë ¥ ìˆìŠµë‹ˆê¹Œ?",
        "ì•± ì‚¬ìš©ì„±ì— ë§Œì¡±í•˜ì‹­ë‹ˆê¹Œ?",
        "ì—°íšŒë¹„ê°€ í•©ë¦¬ì ì…ë‹ˆê¹Œ?",
        "ê³ ê°ì„¼í„° ì‘ëŒ€ í’ˆì§ˆì€?",
        "ì¬ë°œê¸‰ ì ˆì°¨ê°€ í¸ë¦¬í•©ë‹ˆê¹Œ?"
    ],
    "target": {"card_brand": "í˜„ëŒ€ì¹´ë“œ"},
    "sample_size": 2000
})

print(result["cost_breakdown"])
# {
#     "total": "$42"
# }
# vs Claude ì§ì ‘: 2000ëª… Ã— 5ë¬¸í•­ Ã— $0.015 = $150
# ì ˆê°: 72%

# í•˜ì§€ë§Œ...
print("ë¬¸ì œì :")
print("1. ì²« ì„¤ë¬¸ 45ë¶„ ëŒ€ê¸°")
print("2. ë§¤ ì„¤ë¬¸ë§ˆë‹¤ íŒŒì¸íŠœë‹ í•„ìš”")
print("3. ëª¨ë¸ ê´€ë¦¬ ë³µì¡ë„ ì¦ê°€")
print("4. í’ˆì§ˆ ë¶ˆí™•ì‹¤ì„±")
```

**í‰ê°€:**
```python
# ë¹„ìš© vs ë³µì¡ë„
comparison = {
    "ìˆœìˆ˜ Claude": {
        "cost": "$150",
        "complexity": "â­",
        "quality": "â­â­â­â­â­",
        "time": "ì¦‰ì‹œ"
    },
    "Mini FT": {
        "cost": "$42",
        "complexity": "â­â­â­â­",
        "quality": "â­â­â­â­",
        "time": "45ë¶„"
    }
}

# ê²°ë¡ : ë¹„ìš© ì ˆê°ì€ ìˆì§€ë§Œ ë³µì¡ë„ ëŒ€ë¹„ ê°€ì¹˜ ë‚®ìŒ
recommendation = "ì¼ë°˜ì ìœ¼ë¡œ ê¶Œì¥í•˜ì§€ ì•ŠìŒ"
```

### ì „ëµ 3: Few-shot Prompting

**ê°œë…:** íŒŒì¸íŠœë‹ ëŒ€ì‹  í”„ë¡¬í”„íŠ¸ì— ì˜ˆì‹œ í¬í•¨

```python
class FewShotSurveyEngine:
    """ì˜ˆì‹œ ê¸°ë°˜ í”„ë¡¬í”„íŒ…"""
    
    def __init__(self):
        self.gemini_base = genai.GenerativeModel("gemini-1.5-flash")
        self.claude = ClaudeAPI()
    
    def generate_with_examples(self, persona: Dict, question: str, 
                               n_examples: int = 3) -> str:
        """
        Few-shot í”„ë¡¬í”„íŒ…ìœ¼ë¡œ ì‘ë‹µ ìƒì„±
        
        Args:
            n_examples: í”„ë¡¬í”„íŠ¸ì— í¬í•¨í•  ì˜ˆì‹œ ê°œìˆ˜
        """
        
        # 1. Claudeë¡œ ê³ í’ˆì§ˆ ì˜ˆì‹œ ìƒì„±
        examples = []
        for i in range(n_examples):
            # ë¹„ìŠ·í•œ í”„ë¡œí•„ì˜ í˜ë¥´ì†Œë‚˜ ìƒ˜í”Œë§
            example_persona = self._sample_similar_persona(persona)
            
            # Claudeë¡œ ì‘ë‹µ ìƒì„±
            example_response = self.claude.generate(
                example_persona, 
                question
            )
            
            examples.append({
                "persona": example_persona,
                "question": question,
                "response": example_response
            })
        
        # 2. Few-shot í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = self._build_fewshot_prompt(persona, question, examples)
        
        # 3. ì €ë ´í•œ ëª¨ë¸ë¡œ ì¶”ë¡ 
        response = self.gemini_base.generate_content(prompt)
        
        return response.text
    
    def _build_fewshot_prompt(self, persona, question, examples):
        """Few-shot í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        prompt = """ë‹¤ìŒì€ ìœ ì‚¬í•œ í”„ë¡œí•„ì„ ê°€ì§„ ì‚¬ëŒë“¤ì˜ ì‘ë‹µ ì˜ˆì‹œì…ë‹ˆë‹¤:

"""
        
        # ì˜ˆì‹œ ì¶”ê°€
        for i, ex in enumerate(examples, 1):
            prompt += f"""[ì˜ˆì‹œ {i}]
í”„ë¡œí•„: {ex['persona']['age_group']}, {ex['persona']['gender']}, 
        {ex['persona']['region']}, ì†Œë“ {ex['persona']['income']}
ì§ˆë¬¸: {ex['question']}
ì‘ë‹µ: {ex['response']}

"""
        
        # ì‹¤ì œ ì§ˆë¬¸
        prompt += f"""ì´ì œ ë‹¹ì‹ ì˜ í”„ë¡œí•„ë¡œ ê°™ì€ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”:

í”„ë¡œí•„: {persona['age_group']}, {persona['gender']}, 
        {persona['region']}, ì†Œë“ {persona['income']}
ì§ˆë¬¸: {question}
ì‘ë‹µ:"""
        
        return prompt


# ë¹„ìš© ë¶„ì„
engine = FewShotSurveyEngine()

# 2000ëª… ì„¤ë¬¸, ì§ˆë¬¸ 5ê°œ
cost_breakdown = {
    "ì˜ˆì‹œ ìƒì„±": "3 examples Ã— 5 questions Ã— $0.015 = $0.225",
    "ì‹¤ì œ ì‘ë‹µ": "2000ëª… Ã— 5ë¬¸í•­ Ã— $0.002 (Gemini base) = $20",
    "ì´ ë¹„ìš©": "$20.225"
}

# vs Claude ì§ì ‘: $150
# ì ˆê°: 86.5%

# í•˜ì§€ë§Œ...
concerns = {
    "í’ˆì§ˆ": "ì˜ˆì‹œì— ê³¼ë„í•˜ê²Œ ì˜ì¡´, ì¼ë°˜í™” ë¶€ì¡±",
    "ì¼ê´€ì„±": "ì˜ˆì‹œ ì„ íƒì— ë”°ë¼ ì‘ë‹µ í’ˆì§ˆ í¸ì°¨",
    "í”„ë¡¬í”„íŠ¸ ê¸¸ì´": "í† í° ìˆ˜ ì¦ê°€ë¡œ ì‹¤ì œ ë¹„ìš© ë” ë†’ì„ ìˆ˜ ìˆìŒ"
}
```

---

## ğŸ—ï¸ ì˜¨ë””ë§¨ë“œ IPF ìƒì„± ì „ëµ

### í•µì‹¬ ì•„ì´ë””ì–´

**ë¬¸ì œ:**
```
ëª¨ë“  í–‰ë™ ì†ì„±ì„ í•œ ë²ˆì— IPFì— í¬í•¨
â†’ (18 age) Ã— (2 gender) Ã— (17 region) Ã— (6 edu) Ã— (5 card) Ã— (2 netflix) Ã— (2 car)
â†’ 73,440+ ì°¨ì› (ê³„ì‚° ë¶ˆê°€ëŠ¥)
```

**í•´ê²°ì±…:**
```
ì„¤ë¬¸ ì˜ë¢° ì‹œë§ˆë‹¤ í•„ìš”í•œ ì°¨ì›ë§Œ ì¶”ê°€
â†’ (18 age) Ã— (2 gender) Ã— (17 region) Ã— (6 edu) Ã— (5 card)
â†’ 18,360 ì°¨ì› (ì¶©ë¶„íˆ ê°€ëŠ¥!)
```

### êµ¬í˜„: Layered IPF System

```python
class LayeredIPFSystem:
    """ë ˆì´ì–´ ë°©ì‹ IPF ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        # ë² ì´ìŠ¤ ë ˆì´ì–´ (í•­ìƒ ìœ ì§€, 1íšŒë§Œ ìƒì„±)
        self.base_ipf = None  # age, gender, region, education
        
        # í–‰ë™ ë ˆì´ì–´ ìºì‹œ (ìµœëŒ€ 5ê°œ ìœ ì§€)
        self.behavior_layers = {}
        
        # ì™¸ë¶€ ë°ì´í„° ìˆ˜ì§‘ê¸°
        self.data_collector = ExternalDataCollector()
        
        # ìŠ¤í† ë¦¬ì§€ ê´€ë¦¬ì
        self.storage = SmartStorageManager(max_cached=5)
    
    def get_or_create_population(self, required_behaviors: List[str]) -> Dict:
        """
        í•„ìš”í•œ í–‰ë™ ì†ì„±ì´ í¬í•¨ëœ ì¸êµ¬ ë°˜í™˜
        ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±, ìˆìœ¼ë©´ ìºì‹œ í™œìš©
        
        Args:
            required_behaviors: ["card_brand", "netflix"]
            
        Returns:
            {
                "collection": "pop_card_brand_netflix",
                "dimensions": ["age", "gender", "region", "edu", "card_brand", "netflix"],
                "status": "ready" | "generating",
                "created_at": datetime,
                "estimated_time": "10ë¶„"
            }
        """
        
        # ìºì‹œ í‚¤ ìƒì„± (ì •ë ¬í•´ì„œ ì¼ê´€ì„± ìœ ì§€)
        cache_key = "_".join(sorted(required_behaviors))
        
        # ìºì‹œ í™•ì¸
        if cache_key in self.behavior_layers:
            print(f"âœ“ ìºì‹œ ì‚¬ìš©: {cache_key}")
            
            # ì‚¬ìš© í†µê³„ ì—…ë°ì´íŠ¸ (LRU)
            self.storage.update_usage(cache_key)
            
            return self.behavior_layers[cache_key]
        
        # ìºì‹œ ì—†ìŒ â†’ ìƒˆë¡œ ìƒì„±
        print(f"ìƒˆ IPF ìƒì„± í•„ìš”: {cache_key}")
        
        # ë¹„ë™ê¸° ì‘ì—… ì‹œì‘
        job_id = self._start_ipf_generation(required_behaviors)
        
        return {
            "status": "generating",
            "job_id": job_id,
            "estimated_completion": self._estimate_time(required_behaviors),
            "cache_key": cache_key
        }
    
    def _start_ipf_generation(self, behaviors: List[str]) -> str:
        """IPF ìƒì„± ì‘ì—… ì‹œì‘ (ë¹„ë™ê¸°)"""
        
        job_id = str(uuid.uuid4())
        
        # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… íì— ì¶”ê°€
        task = {
            "job_id": job_id,
            "type": "ipf_generation",
            "behaviors": behaviors,
            "status": "pending"
        }
        
        self.job_queue.add(task)
        
        # Celery, RQ, ë˜ëŠ” ê°„ë‹¨í•œ Threadë¡œ ì‹¤í–‰
        threading.Thread(
            target=self._generate_ipf_async,
            args=(job_id, behaviors)
        ).start()
        
        return job_id
    
    def _generate_ipf_async(self, job_id: str, behaviors: List[str]):
        """IPF ìƒì„± (ë¹„ë™ê¸° ì‹¤í–‰)"""
        
        try:
            # 1. ì™¸ë¶€ ë°ì´í„° ìˆ˜ì§‘
            print(f"[{job_id}] ì™¸ë¶€ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            external_marginals = {}
            
            for behavior in behaviors:
                marginal = self.data_collector.get_marginal(behavior)
                external_marginals[behavior] = marginal
                print(f"  âœ“ {behavior} ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
            
            # 2. IPF ì‹¤í–‰
            print(f"[{job_id}] IPF ì‹¤í–‰ ì¤‘...")
            dimensions = ["age_group", "gender", "region", "education"] + behaviors
            
            ipf = IPFGenerator(
                dimensions=dimensions,
                marginals={
                    **self._get_base_marginals(),
                    **external_marginals
                }
            )
            
            population = ipf.generate(total=40_000_000)
            print(f"  âœ“ {len(population):,}ê°œ ê³ ìœ  í”„ë¡œí•„ ìƒì„±")
            
            # 3. MongoDB ì €ì¥
            print(f"[{job_id}] MongoDB ì €ì¥ ì¤‘...")
            cache_key = "_".join(sorted(behaviors))
            collection_name = f"pop_{cache_key}"
            
            self._save_to_mongodb(population, collection_name)
            print(f"  âœ“ {collection_name} ì»¬ë ‰ì…˜ì— ì €ì¥ ì™„ë£Œ")
            
            # 4. ìºì‹œì— ë“±ë¡
            self.behavior_layers[cache_key] = {
                "collection": collection_name,
                "dimensions": dimensions,
                "status": "ready",
                "created_at": datetime.now(),
                "size_mb": self._get_collection_size(collection_name)
            }
            
            # 5. LRU ì •ë¦¬
            self.storage.cleanup_old_caches()
            
            print(f"[{job_id}] ì™„ë£Œ!")
            
        except Exception as e:
            print(f"[{job_id}] ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ë¡œê¹… ë° ì•Œë¦¼
    
    def check_job_status(self, job_id: str) -> Dict:
        """ì‘ì—… ìƒíƒœ í™•ì¸"""
        
        job = self.job_queue.get(job_id)
        
        return {
            "job_id": job_id,
            "status": job["status"],  # pending/running/completed/failed
            "progress": job.get("progress", 0),
            "estimated_remaining": job.get("estimated_remaining", "ì•Œ ìˆ˜ ì—†ìŒ")
        }


class SmartStorageManager:
    """LRU ê¸°ë°˜ ìºì‹œ ê´€ë¦¬"""
    
    def __init__(self, max_cached: int = 5):
        self.max_cached = max_cached
        self.cache_metadata = {}
    
    def update_usage(self, cache_key: str):
        """ìºì‹œ ì‚¬ìš© ê¸°ë¡"""
        
        if cache_key in self.cache_metadata:
            self.cache_metadata[cache_key]["last_used"] = datetime.now()
            self.cache_metadata[cache_key]["use_count"] += 1
    
    def cleanup_old_caches(self):
        """ì˜¤ë˜ëœ ìºì‹œ ì‚­ì œ"""
        
        if len(self.cache_metadata) <= self.max_cached:
            return
        
        # ì‚¬ìš© ë¹ˆë„ + ìµœê·¼ì„± ê¸°ì¤€ ì •ë ¬
        sorted_caches = sorted(
            self.cache_metadata.items(),
            key=lambda x: (
                x[1]["use_count"],  # ìš°ì„ : ì‚¬ìš© íšŸìˆ˜
                x[1]["last_used"]   # ë³´ì¡°: ìµœê·¼ ì‚¬ìš©
            )
        )
        
        # í•˜ìœ„ ì‚­ì œ ëŒ€ìƒ
        to_delete = sorted_caches[:-self.max_cached]
        
        for cache_key, meta in to_delete:
            print(f"ìºì‹œ ì‚­ì œ: {cache_key}")
            print(f"  ë§ˆì§€ë§‰ ì‚¬ìš©: {meta['last_used']}")
            print(f"  ì‚¬ìš© íšŸìˆ˜: {meta['use_count']}")
            
            # MongoDB ì»¬ë ‰ì…˜ ì‚­ì œ
            db[meta["collection"]].drop()
            
            # ë©”íƒ€ë°ì´í„° ì‚­ì œ
            del self.cache_metadata[cache_key]


class ExternalDataCollector:
    """ì™¸ë¶€ ë°ì´í„° ìë™ ìˆ˜ì§‘"""
    
    KNOWN_SOURCES = {
        "card_brand": {
            "source": "ê¸ˆìœµê°ë…ì› ì‹ ìš©ì¹´ë“œ í†µê³„",
            "url": "https://www.fss.or.kr/...",
            "parser": "parse_card_stats",
            "update_frequency": "quarterly"
        },
        "netflix": {
            "source": "ë°©ì†¡í†µì‹ ìœ„ì›íšŒ OTT ì´ìš© ì‹¤íƒœ",
            "url": "https://www.kcc.go.kr/...",
            "parser": "parse_ott_stats",
            "update_frequency": "annually"
        },
        "car_ownership": {
            "source": "êµ­í† êµí†µë¶€ ìë™ì°¨ ë“±ë¡ í†µê³„",
            "url": "https://www.molit.go.kr/...",
            "parser": "parse_car_stats",
            "update_frequency": "monthly"
        }
    }
    
    def get_marginal(self, behavior: str) -> Dict:
        """í–‰ë™ ì†ì„±ì˜ ì£¼ë³€ ë¶„í¬ ê°€ì ¸ì˜¤ê¸°"""
        
        if behavior in self.KNOWN_SOURCES:
            # ìë™ ìˆ˜ì§‘
            source_info = self.KNOWN_SOURCES[behavior]
            
            # ìºì‹œ í™•ì¸ (ì—…ë°ì´íŠ¸ ì£¼ê¸° ê³ ë ¤)
            cached = self._check_cache(behavior, source_info["update_frequency"])
            if cached:
                return cached
            
            # ìƒˆë¡œ ìˆ˜ì§‘
            data = self._crawl_data(source_info["url"])
            parsed = self._parse_data(data, source_info["parser"])
            
            # ìºì‹œ ì €ì¥
            self._save_cache(behavior, parsed)
            
            return parsed
        else:
            # ìˆ˜ë™ ì…ë ¥ í•„ìš”
            raise DataNotFoundError(
                f"{behavior} ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
                f"ê´€ë¦¬ì í˜ì´ì§€ì—ì„œ ìˆ˜ë™ìœ¼ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”."
            )


# API ì—”ë“œí¬ì¸íŠ¸
@app.post("/survey/create")
async def create_survey(request: SurveyRequest):
    """
    ì„¤ë¬¸ ìƒì„± ìš”ì²­
    
    Request:
        {
            "target": {
                "age": ["30-34ì„¸"],
                "card_brand": "í˜„ëŒ€ì¹´ë“œ"  â† í–‰ë™ ì†ì„±
            },
            "sample_size": 2000,
            "questions": [...]
        }
    """
    
    system = LayeredIPFSystem()
    
    # í•„ìš”í•œ í–‰ë™ ì°¨ì› ì¶”ì¶œ
    behaviors = extract_behaviors(request.target)
    
    # ì¸êµ¬ ê°€ì ¸ì˜¤ê¸° (ìºì‹œ or ìƒì„±)
    population = system.get_or_create_population(behaviors)
    
    if population["status"] == "generating":
        # ì²« ìƒì„±: ë¹„ë™ê¸° ì²˜ë¦¬
        return {
            "status": "pending",
            "message": f"ì¸êµ¬ ìƒì„± ì¤‘ì…ë‹ˆë‹¤. ì•½ {population['estimated_time']} ì†Œìš”ë©ë‹ˆë‹¤.",
            "job_id": population["job_id"],
            "check_url": f"/survey/status/{population['job_id']}"
        }
    
    # ìºì‹œ ì¡´ì¬: ì¦‰ì‹œ ì„¤ë¬¸ ì‹¤í–‰
    samples = db[population["collection"]].find(
        build_query(request.target)
    ).limit(request.sample_size)
    
    # ì„¤ë¬¸ ì‹¤í–‰ (í•˜ì´ë¸Œë¦¬ë“œ ë¼ìš°íŒ…)
    router = SmartSurveyRouter()
    results = router.run_survey(samples, request.questions)
    
    return {
        "status": "completed",
        "results": results,
        "execution_time": "2.3ì´ˆ"
    }


@app.get("/survey/status/{job_id}")
async def check_survey_status(job_id: str):
    """ì‘ì—… ìƒíƒœ í™•ì¸"""
    
    system = LayeredIPFSystem()
    status = system.check_job_status(job_id)
    
    return status
```

### ì°¨ì›ë³„ ê³„ì‚° ë³µì¡ë„

| ì°¨ì› êµ¬ì„± | ì…€ ê°œìˆ˜ | IPF ì‹œê°„ | ì €ì¥ ìš©ëŸ‰ | í˜„ì‹¤ì„± |
|---------|--------|---------|----------|-------|
| ê¸°ë³¸ 4ê°œ (ageÃ—genderÃ—regionÃ—edu) | 3,672 | 2ë¶„ | 40GB | âœ… |
| +1 í–‰ë™ (card 5ê°œ) | 18,360 | 5ë¶„ | 42GB | âœ… |
| +2 í–‰ë™ (cardÃ—netflix) | 36,720 | 12ë¶„ | 45GB | âœ… |
| +3 í–‰ë™ (cardÃ—netflixÃ—car) | 73,440 | 25ë¶„ | 50GB | âš ï¸ |
| +4 í–‰ë™ | 147,000+ | 1ì‹œê°„+ | 60GB+ | âŒ |

**ìµœëŒ€ ê¶Œì¥:** 2-3ê°œ í–‰ë™ ì†ì„± ì¶”ê°€

---

## ğŸ’° í˜„ì‹¤ì  ë¹„ìš©/í’ˆì§ˆ ë¹„êµ

### ì›” 10,000ê±´ ê¸°ì¤€ (ì§ˆë¬¸ 5ê°œ)

| ì „ëµ | ì´ˆê¸° íˆ¬ì | ì›” ë¹„ìš© | ì—°ê°„ ì´ ë¹„ìš© | ì‘ë‹µ í’ˆì§ˆ | ë³µì¡ë„ | ì¶”ì²œë„ |
|------|---------|--------|------------|---------|-------|--------|
| **ìˆœìˆ˜ Claude** | $0 | $750 | $9,000 | â­â­â­â­â­ | â­ | âœ… ê¸°ë³¸ |
| **í•˜ì´ë¸Œë¦¬ë“œ** | $500 | $300-400 | $4,100 | â­â­â­â­ | â­â­ | â­ ì¶”ì²œ |
| ì„¤ë¬¸ë³„ Mini FT | $0 | $420 | $5,040 | â­â­â­ | â­â­â­â­ | âŒ ë¹„ì¶” |
| ë²”ìš© íŒŒì¸íŠœë‹ | $700 | $50 | $1,300 | â­â­ | â­â­â­ | âš ï¸ ì¡°ê±´ë¶€ |

**ì‹œë‚˜ë¦¬ì˜¤ë³„ ì¶”ì²œ:**

```python
recommendations = {
    "B2B ë§ì¶¤í˜• ì„¤ë¬¸": {
        "strategy": "ìˆœìˆ˜ Claude",
        "reason": "ì§ˆë¬¸ ë§¤ë²ˆ ë‹¤ë¦„, í’ˆì§ˆ ìµœìš°ì„ "
    },
    "í‘œì¤€ ì¶”ì  ì¡°ì‚¬": {
        "strategy": "ë²”ìš© íŒŒì¸íŠœë‹",
        "reason": "ì§ˆë¬¸ ë°˜ë³µì , ëŒ€ëŸ‰ ì²˜ë¦¬"
    },
    "í•˜ì´ë¸Œë¦¬ë“œ SaaS": {
        "strategy": "í•˜ì´ë¸Œë¦¬ë“œ ë¼ìš°íŒ…",
        "reason": "ë°˜ë³µ + ë§ì¶¤í˜• í˜¼ì¬"
    },
    "MVP/ì´ˆê¸°": {
        "strategy": "ìˆœìˆ˜ Claude",
        "reason": "ë¹ ë¥¸ ê²€ì¦, ë³µì¡ë„ ìµœì†Œí™”"
    }
}
```

### 3ë…„ TCO (Total Cost of Ownership)

```python
# ì‹œë‚˜ë¦¬ì˜¤: ì›” 10,000ê±´, ì§ˆë¬¸ 5ê°œì”©

scenarios = {
    "ìˆœìˆ˜ Claude": {
        "year_1": 750 * 12,  # $9,000
        "year_2": 750 * 12,  # $9,000
        "year_3": 750 * 12,  # $9,000
        "total": 27000
    },
    "í•˜ì´ë¸Œë¦¬ë“œ": {
        "year_1": 500 + (350 * 12),  # $4,700 (ì´ˆê¸° íˆ¬ì í¬í•¨)
        "year_2": 350 * 12,  # $4,200
        "year_3": 350 * 12,  # $4,200
        "total": 13100,
        "savings": 27000 - 13100  # $13,900 (51% ì ˆê°)
    },
    "ë²”ìš© íŒŒì¸íŠœë‹": {
        "year_1": 700 + (50 * 12),  # $1,300
        "year_2": 50 * 12,  # $600
        "year_3": 50 * 12 + 200,  # $800 (ì¬íŒŒì¸íŠœë‹)
        "total": 2700,
        "savings": 27000 - 2700,  # $24,300 (90% ì ˆê°)
        "quality_loss": "35%",  # í’ˆì§ˆ ì†ì‹¤
        "ì ìš© ì¡°ê±´": "ì§ˆë¬¸ 70% ì´ìƒ ë°˜ë³µ"
    }
}
```

---

## ğŸ¯ ìµœì¢… ì¶”ì²œ ë¡œë“œë§µ

### Phase 1: MVP (Month 1-3) - Claude API ì§ì ‘

**ëª©í‘œ:** ì„œë¹„ìŠ¤ ê°œë… ê²€ì¦

```python
class MVPSurveyService:
    """ìµœì†Œ ê¸°ëŠ¥ ì œí’ˆ"""
    
    def __init__(self):
        self.claude = ClaudeAPI()
        self.ipf_base = BaseIPFPopulation()  # ê¸°ë³¸ 4ì°¨ì›ë§Œ
    
    def run_survey(self, targeting, questions, sample_size):
        # 1. ê¸°ë³¸ ì¸êµ¬í†µê³„ë¡œ íƒ€ê²ŸíŒ…
        samples = self.ipf_base.find(targeting).limit(sample_size)
        
        # 2. Claudeë¡œ ì§ì ‘ ì‘ë‹µ ìƒì„±
        results = []
        for persona in samples:
            for q in questions:
                # í–‰ë™ ì†ì„±ì€ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
                if "card_brand" in targeting:
                    q = f"[ë‹¹ì‹ ì€ {targeting['card_brand']} ì‚¬ìš©ìì…ë‹ˆë‹¤] {q}"
                
                response = self.claude.generate(persona, q)
                results.append(response)
        
        return results

# ì²´í¬ë¦¬ìŠ¤íŠ¸
mvp_checklist = [
    "[ ] MongoDB ì„¤ì¹˜",
    "[ ] ê¸°ë³¸ IPF ìƒì„± (4ì°¨ì›)",
    "[ ] Claude API ì—°ë™",
    "[ ] íƒ€ê²ŸíŒ… ì¿¼ë¦¬ êµ¬í˜„",
    "[ ] ë² íƒ€ ì‚¬ìš©ì 5ëª… ëª¨ì§‘",
    "[ ] í”¼ë“œë°± ìˆ˜ì§‘"
]

# ëª©í‘œ ì§€í‘œ
mvp_targets = {
    "ì›” ì„¤ë¬¸ ê±´ìˆ˜": "500-1,000ê±´",
    "ì‚¬ìš©ì ë§Œì¡±ë„": "80% ì´ìƒ",
    "ì‘ë‹µ ì‹œê°„": "5ì´ˆ ì´ë‚´",
    "ë¹„ìš©/ê±´": "$0.75 ì´í•˜"
}
```

### Phase 2: ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ (Month 4-9)

**ëª©í‘œ:** íŒŒì¸íŠœë‹ í•„ìš”ì„± íŒë‹¨

```python
class DataCollectionPhase:
    """ì‚¬ìš© íŒ¨í„´ ë¶„ì„"""
    
    def __init__(self):
        self.usage_logger = UsageLogger()
    
    def log_survey(self, survey_data):
        """ëª¨ë“  ì„¤ë¬¸ ë¡œê¹…"""
        
        self.usage_logger.log({
            "timestamp": datetime.now(),
            "client": survey_data["client"],
            "questions": survey_data["questions"],
            "target": survey_data["target"],
            "sample_size": survey_data["sample_size"],
            "cost": calculate_cost(survey_data)
        })
    
    def analyze_patterns(self):
        """6ê°œì›” í›„ íŒ¨í„´ ë¶„ì„"""
        
        logs = self.usage_logger.get_all()
        
        # ì§ˆë¬¸ í´ëŸ¬ìŠ¤í„°ë§
        clusters = cluster_questions(logs["questions"])
        
        # ë°˜ë³µë„ ê³„ì‚°
        repetition_rate = calculate_repetition(clusters)
        
        # ë„ë©”ì¸ ë¶„í¬
        domains = categorize_domains(clusters)
        
        return {
            "total_surveys": len(logs),
            "unique_questions": len(set(logs["questions"])),
            "repetition_rate": repetition_rate,
            "top_10_domains_coverage": domains[:10].sum() / domains.sum(),
            "monthly_cost": logs["cost"].mean(),
            "recommendation": self._make_recommendation(repetition_rate, domains)
        }
    
    def _make_recommendation(self, repetition_rate, domains):
        """íŒŒì¸íŠœë‹ ì—¬ë¶€ ì¶”ì²œ"""
        
        if repetition_rate > 0.7 and domains[:10].sum() / domains.sum() > 0.8:
            return {
                "action": "í•˜ì´ë¸Œë¦¬ë“œ ì „í™˜ ê¶Œì¥",
                "reason": "ì§ˆë¬¸ 70% ë°˜ë³µ, ë„ë©”ì¸ ìˆ˜ë ´",
                "expected_savings": "50-60%"
            }
        elif repetition_rate > 0.9:
            return {
                "action": "ë²”ìš© íŒŒì¸íŠœë‹ ê³ ë ¤",
                "reason": "ì§ˆë¬¸ 90% ì´ìƒ ë°˜ë³µ",
                "expected_savings": "80-90%"
            }
        else:
            return {
                "action": "Claude API ìœ ì§€",
                "reason": "ì§ˆë¬¸ ë‹¤ì–‘ì„± ë†’ìŒ",
                "savings": "ì—†ìŒ, ë³µì¡ë„ë§Œ ì¦ê°€"
            }

# Phase 2 ì¢…ë£Œ ì‹œ í‰ê°€
phase2_evaluation = DataCollectionPhase().analyze_patterns()

if phase2_evaluation["recommendation"]["action"] == "Claude API ìœ ì§€":
    print("âœ“ Claude API ê³„ì† ì‚¬ìš©")
    print("Phase 3ë¡œ ì§„í–‰í•˜ì§€ ì•ŠìŒ")
else:
    print(f"â†’ Phase 3 ì§„í–‰: {phase2_evaluation['recommendation']['action']}")
```

### Phase 3: ì„ íƒì  ìµœì í™” (Month 10+)

**ì¡°ê±´ ì¶©ì¡± ì‹œì—ë§Œ ì§„í–‰**

```python
# ì§„ì… ì¡°ê±´
PHASE3_CRITERIA = {
    "monthly_volume": 10000,      # ì›” 10,000ê±´ ì´ìƒ
    "repetition_rate": 0.7,       # ì§ˆë¬¸ 70% ë°˜ë³µ
    "domain_convergence": 0.8,    # ìƒìœ„ 10ê°œ ë„ë©”ì¸ì´ 80% ì°¨ì§€
    "cost_ratio": 0.3,            # ë¹„ìš©ì´ ë§¤ì¶œì˜ 30% ì´ìƒ
    "stable_growth": True         # 3ê°œì›” ì—°ì† ì„±ì¥
}

def check_phase3_readiness():
    """Phase 3 ì§„ì… ê°€ëŠ¥ ì—¬ë¶€"""
    
    metrics = get_current_metrics()
    
    checks = {
        "volume": metrics["monthly_volume"] >= PHASE3_CRITERIA["monthly_volume"],
        "repetition": metrics["repetition_rate"] >= PHASE3_CRITERIA["repetition_rate"],
        "domains": metrics["domain_convergence"] >= PHASE3_CRITERIA["domain_convergence"],
        "cost": metrics["cost_ratio"] >= PHASE3_CRITERIA["cost_ratio"],
        "growth": metrics["stable_growth"]
    }
    
    if all(checks.values()):
        return {
            "ready": True,
            "recommendation": "í•˜ì´ë¸Œë¦¬ë“œ ì „í™˜ ì‹œì‘",
            "expected_roi": "6ê°œì›” ë‚´ íˆ¬ì íšŒìˆ˜"
        }
    else:
        return {
            "ready": False,
            "missing": [k for k, v in checks.items() if not v],
            "recommendation": "ì¡°ê±´ ì¶©ì¡± ì‹œê¹Œì§€ Phase 2 ìœ ì§€"
        }

# í•˜ì´ë¸Œë¦¬ë“œ ì „í™˜ (ì¡°ê±´ ì¶©ì¡± ì‹œ)
class HybridTransition:
    """í•˜ì´ë¸Œë¦¬ë“œë¡œ ì „í™˜"""
    
    def execute(self):
        # 1. í•™ìŠµ ë°ì´í„° ìƒì„±
        print("Step 1: íŒŒì¸íŠœë‹ ë°ì´í„° ìƒì„±...")
        training_data = self._create_training_data(
            top_questions=analyze_patterns()["top_questions"],
            sample_size=10000
        )
        # ë¹„ìš©: $450
        
        # 2. Gemini íŒŒì¸íŠœë‹
        print("Step 2: Gemini íŒŒì¸íŠœë‹...")
        tuned_model = finetune_gemini(training_data)
        # ë¹„ìš©: $200
        # ì‹œê°„: 4ì‹œê°„
        
        # 3. í•˜ì´ë¸Œë¦¬ë“œ ë¼ìš°í„° ë°°í¬
        print("Step 3: ë¼ìš°í„° ë°°í¬...")
        router = SmartSurveyRouter(
            finetuned_model=tuned_model,
            claude_api=ClaudeAPI()
        )
        
        # 4. A/B í…ŒìŠ¤íŠ¸
        print("Step 4: A/B í…ŒìŠ¤íŠ¸...")
        ab_test_results = self._run_ab_test(router, duration_days=30)
        
        if ab_test_results["quality_acceptable"] and ab_test_results["cost_savings"] > 0.4:
            print("âœ“ í•˜ì´ë¸Œë¦¬ë“œ ì „í™˜ ì™„ë£Œ")
            return "success"
        else:
            print("âœ— í’ˆì§ˆ ë¶€ì¡±, Claude ìœ ì§€")
            return "rollback"
```

---

## ğŸ’» êµ¬í˜„ ê°€ì´ë“œ

### 1. ê¸°ë³¸ Claude API ì„¤ë¬¸ ì—”ì§„

```python
# survey_engine_basic.py

import anthropic
from typing import Dict, List
from pymongo import MongoClient

class BasicSurveyEngine:
    """ê¸°ë³¸ Claude API ì„¤ë¬¸ ì—”ì§„"""
    
    def __init__(self, claude_api_key: str, mongo_uri: str):
        self.claude = anthropic.Anthropic(api_key=claude_api_key)
        self.db = MongoClient(mongo_uri).survey_db
        
        # ë¹„ìš© ì¶”ì 
        self.cost_tracker = CostTracker()
    
    def run_survey(self, 
                   targeting: Dict,
                   questions: List[str],
                   sample_size: int,
                   additional_context: Dict = None) -> Dict:
        """
        ì„¤ë¬¸ ì‹¤í–‰
        
        Args:
            targeting: {"age": ["30-34ì„¸"], "region": "ì„œìš¸íŠ¹ë³„ì‹œ"}
            questions: ["ì§ˆë¬¸1", "ì§ˆë¬¸2", ...]
            sample_size: 2000
            additional_context: {
                "card_brand": "í˜„ëŒ€ì¹´ë“œ",
                "experiences": ["í•´ì™¸ì—¬í–‰ ê²½í—˜"]
            }
        """
        
        # 1. íƒ€ê²ŸíŒ…
        samples = self._find_target_population(targeting, sample_size)
        print(f"íƒ€ê²Ÿ ì¸êµ¬: {len(samples):,}ëª…")
        
        # 2. ì„¤ë¬¸ ì‹¤í–‰
        results = []
        total_cost = 0
        
        for i, persona in enumerate(samples):
            persona_results = []
            
            for question in questions:
                # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
                prompt = self._build_prompt(
                    persona, 
                    question,
                    additional_context
                )
                
                # Claude API í˜¸ì¶œ
                response = self.claude.messages.create(
                    model="claude-sonnet-4-20250514",
                    max_tokens=500,
                    messages=[{"role": "user", "content": prompt}]
                )
                
                answer = response.content[0].text
                cost = self._calculate_cost(response.usage)
                total_cost += cost
                
                persona_results.append({
                    "question": question,
                    "answer": answer,
                    "cost": cost
                })
            
            results.append({
                "persona_id": persona["person_id"],
                "persona": persona,
                "responses": persona_results
            })
            
            # ì§„í–‰ë¥  ì¶œë ¥
            if (i + 1) % 100 == 0:
                print(f"ì§„í–‰: {i+1}/{len(samples)} ({(i+1)/len(samples)*100:.1f}%)")
        
        # 3. ê²°ê³¼ ë°˜í™˜
        return {
            "results": results,
            "statistics": {
                "total_responses": len(samples) * len(questions),
                "total_cost": f"${total_cost:.2f}",
                "avg_cost_per_response": f"${total_cost/(len(samples)*len(questions)):.4f}",
                "execution_time": f"{execution_time:.1f}ì´ˆ"
            }
        }
    
    def _build_prompt(self, persona, question, additional_context):
        """í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        prompt = f"""ë‹¹ì‹ ì€ ë‹¤ìŒê³¼ ê°™ì€ íŠ¹ì„±ì„ ê°€ì§„ í•œêµ­ì¸ì…ë‹ˆë‹¤:

[ê¸°ë³¸ í”„ë¡œí•„]
ì—°ë ¹: {persona['age_group']}
ì„±ë³„: {persona['gender']}
ê±°ì£¼ì§€: {persona['region']}
í•™ë ¥: {persona['education']}
ì§ì—…: {persona['occupation']}
ì†Œë“: {persona['income']}
"""
        
        # ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ (í–‰ë™/ê²½í—˜)
        if additional_context:
            prompt += "\n[ë‹¹ì‹ ì˜ ê²½í—˜/ìƒí™©]\n"
            
            if "card_brand" in additional_context:
                prompt += f"- {additional_context['card_brand']} ì‚¬ìš© ì¤‘\n"
            
            if "experiences" in additional_context:
                for exp in additional_context["experiences"]:
                    prompt += f"- {exp}\n"
        
        prompt += f"""
ìœ„ í”„ë¡œí•„ì˜ ì…ì¥ì—ì„œ ì•„ë˜ ì§ˆë¬¸ì— ìì—°ìŠ¤ëŸ½ê³  í˜„ì‹¤ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
ë‹µë³€ì€ 100-200ì ì´ë‚´ë¡œ, êµ¬ì²´ì ì¸ ì´ìœ ì™€ í•¨ê»˜ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {question}

ë‹µë³€:"""
        
        return prompt
    
    def _find_target_population(self, targeting, sample_size):
        """íƒ€ê²Ÿ ì¸êµ¬ ì¶”ì¶œ"""
        
        query = {}
        
        if "age_group" in targeting:
            query["age_group"] = {"$in": targeting["age_group"]}
        
        if "region" in targeting:
            query["region"] = targeting["region"]
        
        if "gender" in targeting:
            query["gender"] = targeting["gender"]
        
        return list(
            self.db.population.find(query).limit(sample_size)
        )
    
    def _calculate_cost(self, usage):
        """ë¹„ìš© ê³„ì‚°"""
        
        # Claude Sonnet 4 ê°€ê²©
        input_cost = usage.input_tokens * (3 / 1_000_000)
        output_cost = usage.output_tokens * (15 / 1_000_000)
        
        return input_cost + output_cost


# ì‚¬ìš© ì˜ˆì‹œ
engine = BasicSurveyEngine(
    claude_api_key="sk-ant-...",
    mongo_uri="mongodb://localhost:27017"
)

result = engine.run_survey(
    targeting={
        "age_group": ["30-34ì„¸", "35-39ì„¸"],
        "region": "ì„œìš¸íŠ¹ë³„ì‹œ"
    },
    questions=[
        "í˜„ ì •ë¶€ ê²½ì œ ì •ì±…ì— ë§Œì¡±í•˜ì‹­ë‹ˆê¹Œ?",
        "í˜„ì¬ ë¶€ë™ì‚° ì •ì±…ì´ íš¨ê³¼ì ì´ë¼ê³  ìƒê°í•˜ì‹­ë‹ˆê¹Œ?",
        "ê³ ìš© ì•ˆì •ì„±ì„ ì²´ê°í•˜ì‹­ë‹ˆê¹Œ?"
    ],
    sample_size=1000,
    additional_context={
        "card_brand": "í˜„ëŒ€ì¹´ë“œ"
    }
)

print(result["statistics"])
```

### 2. ì˜¨ë””ë§¨ë“œ IPF + í™•ë¥ ì  ì†ì„± í• ë‹¹

```python
# ondemand_ipf.py

class OnDemandIPFService:
    """ì˜¨ë””ë§¨ë“œ IPF ìƒì„± + í™•ë¥ ì  ì†ì„± í• ë‹¹"""
    
    def __init__(self):
        self.ipf_system = LayeredIPFSystem()
        self.behavior_assigner = BehaviorAttributeAssigner()
    
    def handle_survey_request(self, request: Dict) -> Dict:
        """
        ì„¤ë¬¸ ìš”ì²­ ì²˜ë¦¬
        
        request = {
            "targeting": {
                "age": ["30-34ì„¸"],
                "card_brand": "í˜„ëŒ€ì¹´ë“œ"  â† í–‰ë™ ì†ì„± í•„ìš”
            },
            "questions": [...],
            "sample_size": 2000
        }
        """
        
        # 1. í•„ìš”í•œ í–‰ë™ ì°¨ì› íŒŒì•…
        required_behaviors = self._extract_behaviors(request["targeting"])
        
        if required_behaviors:
            # 2-A. IPF ë°©ì‹: ì™¸ë¶€ ë°ì´í„° ê²°í•©
            population = self.ipf_system.get_or_create_population(required_behaviors)
            
            if population["status"] == "generating":
                return {
                    "status": "pending",
                    "message": "ì¸êµ¬ ìƒì„± ì¤‘... (10-20ë¶„)",
                    "job_id": population["job_id"]
                }
            
            # IPFë¡œ ìƒì„±ëœ ì¸êµ¬ ì‚¬ìš©
            samples = db[population["collection"]].find(
                self._build_query(request["targeting"])
            ).limit(request["sample_size"])
        
        else:
            # 2-B. í™•ë¥ ì  í• ë‹¹ ë°©ì‹: ì¦‰ì‹œ ìƒì„±
            base_samples = db.population.find(
                self._build_base_query(request["targeting"])
            ).limit(request["sample_size"] * 2)  # ì—¬ìœ ìˆê²Œ
            
            # í™•ë¥ ì ìœ¼ë¡œ ì†ì„± í• ë‹¹ í›„ í•„í„°ë§
            samples = []
            for persona in base_samples:
                # í–‰ë™ ì†ì„± í• ë‹¹
                extended = self.behavior_assigner.assign(persona)
                
                # íƒ€ê²Ÿ ì¡°ê±´ ë§Œì¡±í•˜ëŠ”ì§€ í™•ì¸
                if self._matches_targeting(extended, request["targeting"]):
                    samples.append(extended)
                
                if len(samples) >= request["sample_size"]:
                    break
        
        # 3. ì„¤ë¬¸ ì‹¤í–‰
        engine = BasicSurveyEngine()
        results = engine.run_survey(
            samples=samples,
            questions=request["questions"]
        )
        
        return {
            "status": "completed",
            "results": results
        }


class BehaviorAttributeAssigner:
    """í™•ë¥ ì  í–‰ë™ ì†ì„± í• ë‹¹"""
    
    def assign(self, persona: Dict) -> Dict:
        """í˜ë¥´ì†Œë‚˜ì— í–‰ë™ ì†ì„± ì¶”ê°€"""
        
        extended = persona.copy()
        
        # ì‹ ìš©ì¹´ë“œ ë¸Œëœë“œ
        extended["card_brand"] = self._assign_card_brand(persona)
        
        # ë„·í”Œë¦­ìŠ¤
        extended["netflix"] = self._assign_netflix(persona)
        
        # ìë™ì°¨
        extended["car_ownership"] = self._assign_car(persona)
        
        return extended
    
    def _assign_card_brand(self, persona):
        """ì‹ ìš©ì¹´ë“œ ë¸Œëœë“œ í™•ë¥ ì  í• ë‹¹"""
        
        # ê¸°ë³¸ ì‹œì¥ ì ìœ ìœ¨
        base_weights = {
            "ì‹ í•œì¹´ë“œ": 0.24,
            "ì‚¼ì„±ì¹´ë“œ": 0.22,
            "í˜„ëŒ€ì¹´ë“œ": 0.18,
            "KBêµ­ë¯¼ì¹´ë“œ": 0.16,
            None: 0.20  # ë¯¸ë³´ìœ 
        }
        
        # ì†Œë“ë³„ ì¡°ì •
        if persona["income"] in ["7000-8000ë§Œì›", "1ì–µì› ì´ìƒ"]:
            # ê³ ì†Œë“: í”„ë¦¬ë¯¸ì—„ ì¹´ë“œ ì„ í˜¸
            base_weights["í˜„ëŒ€ì¹´ë“œ"] *= 1.5
            base_weights["ì‚¼ì„±ì¹´ë“œ"] *= 1.3
        
        # ì—°ë ¹ë³„ ì¡°ì •
        if persona["age_group"] in ["20-24ì„¸", "25-29ì„¸"]:
            # ì Šì€ì¸µ: ë¯¸ë³´ìœ  í™•ë¥  ë†’ìŒ
            base_weights[None] *= 2.0
        
        # ì •ê·œí™”
        total = sum(base_weights.values())
        weights = {k: v/total for k, v in base_weights.items()}
        
        # ë¬´ì‘ìœ„ ì„ íƒ
        brands = list(weights.keys())
        probs = list(weights.values())
        
        return np.random.choice(brands, p=probs)
```

---

## ğŸ“ ë‹¤ìŒ ì•¡ì…˜ ì•„ì´í…œ

### ì¦‰ì‹œ ì‹¤í–‰ (ì´ë²ˆ ì£¼)

```python
week_1_tasks = [
    {
        "task": "MongoDB ì„¤ì¹˜ ë° í…ŒìŠ¤íŠ¸",
        "time": "1ì‹œê°„",
        "priority": "high"
    },
    {
        "task": "Claude API í‚¤ ë°œê¸‰",
        "time": "10ë¶„",
        "priority": "high"
    },
    {
        "task": "ê¸°ë³¸ IPF ìƒì„± (4ì°¨ì›)",
        "time": "30ë¶„",
        "priority": "high"
    },
    {
        "task": "BasicSurveyEngine êµ¬í˜„",
        "time": "2ì‹œê°„",
        "priority": "high"
    },
    {
        "task": "100ëª… ìƒ˜í”Œ í…ŒìŠ¤íŠ¸",
        "time": "1ì‹œê°„",
        "priority": "medium"
    }
]
```

### 1ê°œì›” ë‚´

```python
month_1_tasks = [
    {
        "task": "ë² íƒ€ ì‚¬ìš©ì 5ëª… ëª¨ì§‘",
        "deliverable": "ì‹¤ì œ ì„¤ë¬¸ 5ê±´ ì§„í–‰"
    },
    {
        "task": "ë¹„ìš© ì¶”ì  ì‹œìŠ¤í…œ êµ¬ì¶•",
        "deliverable": "ëŒ€ì‹œë³´ë“œ"
    },
    {
        "task": "ì‚¬ìš© íŒ¨í„´ ë¡œê¹…",
        "deliverable": "ì§ˆë¬¸ DB êµ¬ì¶•"
    },
    {
        "task": "í™•ë¥ ì  ì†ì„± í• ë‹¹ êµ¬í˜„",
        "deliverable": "BehaviorAttributeAssigner í´ë˜ìŠ¤"
    }
]
```

### 6ê°œì›” í‰ê°€

```python
month_6_evaluation = {
    "metrics_to_track": [
        "ì›” ì„¤ë¬¸ ê±´ìˆ˜",
        "ì§ˆë¬¸ ë°˜ë³µë„",
        "ë„ë©”ì¸ ë¶„í¬",
        "ë¹„ìš© ëŒ€ë¹„ ë§¤ì¶œ",
        "ì‚¬ìš©ì ë§Œì¡±ë„"
    ],
    "decision_criteria": {
        "Claude ìœ ì§€": "ì§ˆë¬¸ ë‹¤ì–‘ì„± ë†’ìŒ (ë°˜ë³µë„ <50%)",
        "í•˜ì´ë¸Œë¦¬ë“œ ì „í™˜": "ë°˜ë³µë„ 60-80%, ë„ë©”ì¸ ìˆ˜ë ´",
        "ë²”ìš© íŒŒì¸íŠœë‹": "ë°˜ë³µë„ >90%, ëŒ€ëŸ‰ ì²˜ë¦¬"
    }
}
```

---

## âš ï¸ í•µì‹¬ ê²½ê³ 

### 1. íŒŒì¸íŠœë‹ì€ ë§ŒëŠ¥ì´ ì•„ë‹™ë‹ˆë‹¤

```
âŒ ì˜ëª»ëœ ê°€ì •: "íŒŒì¸íŠœë‹í•˜ë©´ ëª¨ë“  ì„¤ë¬¸ì„ ì €ë ´í•˜ê²Œ ì²˜ë¦¬"
âœ… í˜„ì‹¤: "í•™ìŠµí•œ ë„ë©”ì¸ë§Œ íš¨ê³¼ì , ë‚˜ë¨¸ì§€ëŠ” í’ˆì§ˆ í•˜ë½"

ì˜ˆì‹œ:
- í•™ìŠµ: "ì •ë¶€ ì •ì±… ë§Œì¡±ë„" (ì¼ë°˜ì )
- ì‹¤ì œ: "í˜„ëŒ€ì¹´ë“œ Mí¬ì¸íŠ¸ ì ë¦½ë¥ " (ì´ˆêµ¬ì²´ì )
â†’ íŒŒì¸íŠœë‹ ëª¨ë¸: ì—‰ëš±í•œ ë‹µë³€ ê°€ëŠ¥
```

### 2. ì„œë¹„ìŠ¤ ëª¨ë¸ë¶€í„° í™•ì¸í•˜ì„¸ìš”

```python
service_model_check = {
    "ì§ˆë¬¸": "ìš°ë¦¬ ì„œë¹„ìŠ¤ì˜ ì§ˆë¬¸ íŒ¨í„´ì€?",
    "ë‹µë³€": [
        "ë§¤ë²ˆ ë‹¤ë¦„ (B2B ë§ì¶¤í˜•)" â†’ "Claude API ìœ ì§€",
        "70% ë°˜ë³µ (í…œí”Œë¦¿ + ë§ì¶¤)" â†’ "í•˜ì´ë¸Œë¦¬ë“œ",
        "90% ê³ ì • (ì¶”ì  ì¡°ì‚¬)" â†’ "íŒŒì¸íŠœë‹"
    ]
}
```

### 3. ì¡°ê¸° ìµœì í™”ì˜ í•¨ì •

```
Phase 1 (ì²« 3ê°œì›”): Claude APIë§Œ ì‚¬ìš©
â†’ ê°„ë‹¨, ë¹ ë¦„, í’ˆì§ˆ ìµœê³ 

Phase 2 (3-9ê°œì›”): ë°ì´í„° ìˆ˜ì§‘ + ë¶„ì„
â†’ ì‹¤ì œ ì‚¬ìš© íŒ¨í„´ íŒŒì•…

Phase 3 (ì¡°ê±´ ì¶©ì¡± ì‹œ): ìµœì í™”
â†’ ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •

âŒ ë‚˜ìœ ì‚¬ë¡€: "ì¼ë‹¨ íŒŒì¸íŠœë‹ë¶€í„°"
âœ… ì¢‹ì€ ì‚¬ë¡€: "ê²€ì¦ í›„ ì„ íƒì  ìµœì í™”"
```

---

**ì‘ì„±ì¼**: 2026-01-17  
**ë²„ì „**: 2.0 (ìˆ˜ì •íŒ)  
**ì´ì „ ë²„ì „ê³¼ì˜ ì°¨ì´**: íŒŒì¸íŠœë‹ì˜ í•œê³„ ëª…ì‹œ, í˜„ì‹¤ì  ì „ëµìœ¼ë¡œ ìˆ˜ì •
